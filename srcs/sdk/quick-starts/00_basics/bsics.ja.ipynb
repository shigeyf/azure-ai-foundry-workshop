{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure AI Foundry の基礎\n",
    "\n",
    "このノートでは、Azure AI Foundry の Azure AI Project SDK を使ってアプリケーションを開発する上で必要な項目について学習します。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前提条件\n",
    "\n",
    "このノートの内容を学習するにあたって、以下が必要になります。\n",
    "\n",
    "- Visial Studio Code または このノートブックを実行可能な Jupyter が動作する環境\n",
    "- Azure サブスクリプション\n",
    "- 作成済みの Azure AI Foundry プロジェクトとデプロイしたモデル\n",
    "- Python 3.8 以降\n",
    "- Python に関する基礎知識\n",
    "- 必要な Python パッケージ（下記のコードでインストールする）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要な Python パッケージのインストール\n",
    "%pip install python-dotenv azure-identity azure-ai-projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure AI Project SDK\n",
    "\n",
    "Azure AI Project SDK では以下の機能のための API が提供されています。\n",
    "\n",
    "- プロジェクトに接続されたリソースの管理\n",
    "  - Azure AI Foundry プロジェクト内の接続を列挙し、接続プロパティを取得します。\n",
    "  - 例えば、Azure OpenAI接続に関連する推論エンドポイントURLや認証情報を取得します。\n",
    "- 認証された推論クライアントの取得\n",
    "  - 認証された推論クライアントを取得して、Azure AI Foundry プロジェクト内のデフォルトの Azure OpenAI または AIサービスへの接続を使ってチャット補完を行います。\n",
    "  - `openai` パッケージの Azure Open AI クライアント、または、`azure-ai-inference` パッケージのクライアントをサポートします。\n",
    "- AI エージェントの開発\n",
    "  - OpenAI, Microsoft, その他の LLM プロバイダーから提供されているモデル、ツール、および、機能が広範囲に提供されたエコシステムを活用して、Azure AI Agent Service を使用してエージェントを開発します。\n",
    "  - Azure AI Agent Service は、幅広い生成 AI ユースケースのためのエージェントの構築を可能にします。\n",
    "  - このパッケージは現在プレビュー中です。\n",
    "- AI アプリケーションの評価の実行\n",
    "  - 様々な評価ロジックと指標を使用して、生成 AI アプリケーションのパフォーマンスを評価するための評価を実行します。\n",
    "  - 品質、リスク、安全性のための組み込み評価ロジックが含まれており、特定のニーズに合わせたカスタム評価ロジックを含めることもできます。\n",
    "- AI アプリケーションの監視\n",
    "  - OpenTelemetry トレースを有効にすることができます。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Azure AI Foundry プロジェクトへの接続のための資格情報の設定\n",
    "\n",
    "Azure AI Foundry プロジェクトへの接続のための認証を行うには、Microsoft Entra ID のユーザーが必要となります。\n",
    "Azure AI Foundry プロジェクトを使ったアプリケーションでは、`TokenCredential` インターフェイスを実装するオブジェクトが必要となります。\n",
    "このノートのコード サンプルでは、​​`DefaultAzureCredential` を使用しています。これを実行するには、以下が必要となります：\n",
    "\n",
    "- 共同作成者 (Contributor) ロール\n",
    "  - 接続するユーザーにこのロールの割り当ては、Azure ポータルの Azure AI プロジェクト リソースの [アクセス制御 (IAM)] タブから行うことができます。\n",
    "- Azure CLI がインストールされていること\n",
    "- az login を実行して、Azure アカウントにログインしていること\n",
    "- 複数の Azure サブスクリプションがある場合は、Azure AI プロジェクト リソースを含むサブスクリプションが既定のサブスクリプションである必要があります。\n",
    "  以下のコマンドを実行して、すべてのサブスクリプションの一覧を表示し、どのサブスクリプションが既定の設定であるかを確認します。\n",
    "\n",
    "  ```bash\n",
    "  az account list --output table\n",
    "  ```\n",
    "\n",
    "  以下のコマンドを実行して、既定のサブスクリプションを変更することができます。\n",
    "\n",
    "  ```bash\n",
    "  az account set --subscription \"Your Subscription ID or Name\"\n",
    "  ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# Azure 資格情報の初期化\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    print(f\"✓ Azure 資格情報の初期化が成功しました.\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Azure 資格情報の初期化が以下の理由で失敗しました: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Azure AI Foundry プロジェクトへの認証と接続\n",
    "\n",
    "`AIProjectClient` のクラスファクトリメソッド `from_connection_string` を使って AI Project クライアントを作成します。\n",
    "`from_connection_string` では、環境変数 `PROJECT_CONNECTION_STRING` で指定したプロジェクト接続名を使用します。\n",
    "\n",
    "`AIProjectClient` の同期クライアントを作成するには、次の手順を実行します：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from azure.ai.projects import AIProjectClient\n",
    "\n",
    "# 環境変数の読み込み\n",
    "load_dotenv('.env', override=True)\n",
    "\n",
    "try:\n",
    "    project_client = AIProjectClient.from_connection_string(\n",
    "        conn_str=os.getenv(\"PROJECT_CONNECTION_STRING\"),\n",
    "        credential=credential,\n",
    "    )\n",
    "    print(f\"✓ Azure AI プロジェクト クライアント (AIProjectClient) の初期化が成功しました.\")\n",
    "except Exception as e:\n",
    "    print(\n",
    "        f\"✗ Azure AI プロジェクト クライアント (AIProjectClient) の初期化が以下の理由で失敗しました: {str(e)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "非同期クライアントを作成する場合は、追加パッケージ `aiohttp` をインストールします。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install aiohttp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "非同期クライアントを作成する場合は、上記のコードサンプルも更新します。\n",
    "`asyncio` をインポートして、`azure.ai.projects.aio` 名前空間から `AIProjectClient` をインポートします。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "from azure.ai.projects.aio import AIProjectClient\n",
    "\n",
    "# 環境変数の読み込み\n",
    "load_dotenv('.env', override=True)\n",
    "\n",
    "try:\n",
    "    project_client_async = AIProjectClient.from_connection_string(\n",
    "        conn_str=os.getenv(\"PROJECT_CONNECTION_STRING\"),\n",
    "        credential=credential,\n",
    "    )\n",
    "    print(f\"✓ Azure AI プロジェクト クライアント (AIProjectClient) の初期化が成功しました.\")\n",
    "except Exception as e:\n",
    "    print(\n",
    "        f\"✗ Azure AI プロジェクト クライアント (AIProjectClient) の初期化が以下の理由で失敗しました: {str(e)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Azure AI Foundry プロジェクトの接続リソースの確認\n",
    "\n",
    "Azure AI Foundry ポータルでは [管理センター] が用意されています。\n",
    "[管理センター] を開くと、プロジェクトに [接続されたリソース (Connected Resources)] というタブが表示されます。\n",
    "AI プロジェクト クライアントの `connections` を使用すると、接続されたリソースを列挙し、それぞれの接続プロパティ (`ConnectionProperties`) を取得できます。\n",
    "接続プロパティ (`ConnectionProperties`) には、リソースのエンドポイント URL や認証資格情報などが含まれます。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 すべての接続のプロパティを取得する\n",
    "\n",
    "Azure AI Foundry プロジェクト内のすべての接続のプロパティを一覧表示するには以下を実行します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the properties of all connections of AIProject\n",
    "connections = project_client.connections.list()\n",
    "print(f\"==> AI プロジェクトのすべての接続を列挙します ({len(connections)} 個の接続が見つかりました):\")\n",
    "for connection in connections:\n",
    "    print(connection)\n",
    "\n",
    "for connection in connections:\n",
    "    print(f\" - {connection.name}\")\n",
    "    print(f\"    connection_type:     {connection.connection_type}\")\n",
    "    print(f\"    authentication_type: {connection.authentication_type}\")\n",
    "    print(f\"    endpoint_url:        {connection.endpoint_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 特定のタイプのすべての接続のプロパティを取得する\n",
    "\n",
    "Azure AI Foundry プロジェクト内の特定のタイプの接続のプロパティを一覧表示するには以下を実行します。\n",
    "ここでは Azure OpenAI サービスのタイプを特定する。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects.models import ConnectionType\n",
    "\n",
    "connections = project_client.connections.list(\n",
    "    connection_type=ConnectionType.AZURE_OPEN_AI,\n",
    ")\n",
    "for connection in connections:\n",
    "    print(connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 デフォルト接続のプロパティを取得する\n",
    "\n",
    "特定のタイプ (ここでは Azure OpenAI) のデフォルト接続のプロパティと視覚情報を取得する。\n",
    "\n",
    "`include_credentials=True` で呼び出しが行われた場合、`connection.authentication_type` の値に応じて、`connection.key` または `connection.token_credential` のいずれかが挿入されます。それ以外の場合は、両方とも `None` (`null`) になります。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = project_client.connections.get_default(\n",
    "    connection_type=ConnectionType.AZURE_OPEN_AI,\n",
    "    include_credentials=True,  # Optional. Defaults to \"False\".\n",
    ")\n",
    "print(connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 接続名で接続のプロパティを取得する\n",
    "\n",
    "`connection_name` という名前の接続の接続プロパティを取得する。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_name = \"AzureAISearch\"\n",
    "connection = project_client.connections.get(\n",
    "    connection_name=connection_name,\n",
    "    include_credentials=True  # Optional. Defaults to \"False\"\n",
    ")\n",
    "print(connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 認証済みの ChatCompletionsClient を取得する\n",
    "\n",
    "Azure AI Foundry プロジェクトには、チャット補完をサポートする 1 つ以上の AI モデルがデプロイされている場合があります。\n",
    "\n",
    "これらは、OpenAI のモデル、Microsoft のモデル、または、他のプロバイダーのモデルです。\n",
    "以下のコードサンプルを使用して、`azure-ai-inference` パッケージの `get_chat_completions_client` を使って、既に認証済みの `ChatCompletionsClient` を取得し、チャット補完呼び出しを実行します。\n",
    "\n",
    "`azure-ai-inference` パッケージをインストールして、コードサンプルを実行します。\n",
    "\n",
    "`get_chat_completions_client` では、`MODEL_NAME` は `.env` ファイルに記載したモデルのデプロイ名で実行します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-ai-inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.inference.models import UserMessage\n",
    "\n",
    "inference_client = project_client.inference.get_chat_completions_client()\n",
    "\n",
    "response = inference_client.complete(\n",
    "    model=os.getenv(\"MODEL_NAME\"),  # Model deployment name\n",
    "    messages=[UserMessage(content=\"1マイルは何フィートですか?\")],\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 認証済みの AzureOpenAI クライアントを取得する\n",
    "\n",
    "Azure AI Foundry プロジェクトには、チャット補完をサポートする 1 つ以上の OpenAI モデルがデプロイされている場合があります。\n",
    "\n",
    "以下のコードを使用して、`openai` パッケージから既に認証済みの AzureOpenAI を取得し、チャット補完呼び出しを実行します。\n",
    "\n",
    "`openai` パッケージをインストールして、コードサンプルを実行します。\n",
    "\n",
    "`get_chat_completions_client` では、`MODEL_NAME` は `.env` ファイルに記載したモデルのデプロイ名で実行します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoai_client = project_client.inference.get_azure_openai_client(\n",
    "    api_version=os.getenv(\"MODEL_API_VERSION\"),\n",
    ")\n",
    "\n",
    "response = aoai_client.chat.completions.create(\n",
    "    model=os.getenv(\"MODEL_NAME\"),  # Model deployment name\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"1マイルは何フィートですか?\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
