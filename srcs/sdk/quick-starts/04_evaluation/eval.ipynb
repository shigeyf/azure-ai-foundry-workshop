{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# クイックスタート4\n",
    "\n",
    "このノートのクイックスタートは、Microsoft の Azure AI Foundry を使って 推論チャットの結果を評価するアプリケーションの開発を行うための学習ノートです。\n",
    "\n",
    "※この内容は 2025年2月時点での仕様等に基づくものです。仕様やドキュメントの変更に伴い、この内容が古くなる可能性があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前提条件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このノートの内容を学習するにあたって、以下が必要になります。\n",
    "\n",
    "- Visial Studio Code または このノートブックを実行可能な Jupyter が動作する環境\n",
    "- Azure サブスクリプション\n",
    "- 作成済みの Azure AI Foundry プロジェクトとデプロイしたモデル\n",
    "- Azure AI Foundry プロジェクトに接続済みの Application Insights インスタンス（トレースに利用） \n",
    "- Python 3.8 以降\n",
    "- Python に関する基礎知識\n",
    "- 必要な Python パッケージ（下記のコードでインストールする）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要な Python パッケージのインストール\n",
    "%pip install python-dotenv azure-identity azure-ai-projects azure-ai-inference azure-ai-evaluation azure-ai-ml azure-search-documents azure-core-tracing-opentelemetry azure-monitor-opentelemetry opentelemetry-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure AI Foundry で 推論モデルの結果に対する評価を行うアプリを開発する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このノートでは、Azure AI Foundry SDK を使用して、推論モデルを使用したチャットアプリケーションのクエリ・結果等に対する評価を行うアプリケーションを開発する方法について説明します。\n",
    "\n",
    "AI の評価は、AI アプリケーションの導入効果を最大化し、ビジネスにおける AI 活用を成功に導くためｎに対する信頼と信用を築くための 生成 AI アプリケーションのライフサイクルの不可欠な要素です。AI アプリケーションが、コンテキストに基づかない、無関係または一貫性のない、捏造された出力を生成する可能性があると、その結果、アプリケーションのエクスペリエンスが悪化したり、誤った情報に基づく決断がなされたり、組織が悪意のある攻撃にさらされたり、その他のさまざまな悪影響が生じたりする可能性があります。AIアプリケーションの品質評価や信頼性評価が重要となります。\n",
    "\n",
    "`azure.ai.projects` と `azure.ai.evaluation` のライブラリを使用して、評価アプリケーションを開発します。\n",
    "ここで開発するアプリケーションは、事前に準備済みの評価データセットをアップロードして、クラウド（リモート）で評価を行います。\n",
    "評価はローカルで実施することもできます。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このクイック スタートを始める前に、Azure AI Foundry ポータルから、ハブ リソースとプロジェクト リソースを作成して `gpt-4o` または `gpt-4o-mini` モデルをプロジェクトへデプロイしてください。\n",
    "\n",
    "エージェントをサポートするモデルには制限があります。[技術ドキュメント](https://learn.microsoft.com/ja-jp/azure/ai-services/agents/concepts/model-region-support?tabs=python) を参照して、適切なモデルとバージョンのエージェントをデプロイします。\n",
    "\n",
    "> [Azure AI Foundry プレイグラウンドのクイックスタート](https://learn.microsoft.com/ja-jp/azure/ai-studio/quickstarts/get-started-playground) を完了している場合、必要な作業は完了しています。\n",
    "\n",
    "Visual Studio Code でこのノートを開き、[ドキュメントのこのセクション](https://code.visualstudio.com/docs/python/environments#_creating-environments) を参考にしながら、ワークスペースに Python 仮想環境を作成します。仮想環境を作成する際には、このフォルダにある `requirements.txt` を選択すると、このノートの Python アプリケーションコードの実行に必要なライブラリを Python 仮想環境にインストールすることができます。\n",
    "\n",
    "仮想環境の準備ができたら、このノートにある Python コードをステップごとに実行します。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### チャットアプリのコードサンプル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. AI プロジェクトに接続します"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[クイックスタート3](../03_rag_chat/rag_chat.ipynb) で実行した手順と同様に、AI プロジェクトに接続し、SDK のトレースを有効にします。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from opentelemetry import trace\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "tracer = trace.get_tracer(__name__)\n",
    "\n",
    "load_dotenv('.env', override=True)\n",
    "project_connection_string = os.getenv('PROJECT_CONNECTION_STRING')\n",
    "model_name_string = os.getenv('MODEL_NAME')\n",
    "model_api_version_string = os.getenv('MODEL_API_VERSION')\n",
    "\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    print(f\"✅ Azure 資格情報の初期化が成功しました.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Azure 資格情報の初期化が以下の理由で失敗しました: {str(e)}\")\n",
    "\n",
    "try:\n",
    "    project = AIProjectClient.from_connection_string(\n",
    "        conn_str=project_connection_string,\n",
    "        credential=credential\n",
    "    )\n",
    "    print(f\"✅ プロジェクトクライアントの初期化が成功しました.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ プロジェクトクライアントの初期化が以下の理由で失敗しました: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下のコードを実行して、トレースを有効にします。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.inference.tracing import AIInferenceInstrumentor\n",
    "from azure.monitor.opentelemetry import configure_azure_monitor\n",
    "from azure.core.settings import settings\n",
    "\n",
    "# Enable Azure SDK tracing with either of two lines:\n",
    "os.environ[\"AZURE_SDK_TRACING_IMPLEMENTATION\"] = \"opentelemetry\"\n",
    "settings.tracing_implementation = \"opentelemetry\"\n",
    "\n",
    "# Enable tracing\n",
    "AIInferenceInstrumentor().instrument()\n",
    "# enable logging message contents\n",
    "os.environ[\"AZURE_TRACING_GEN_AI_CONTENT_RECORDING_ENABLED\"] = \"true\"\n",
    "\n",
    "application_insights_connection_string = project.telemetry.get_connection_string()\n",
    "if not application_insights_connection_string:\n",
    "    print(\"❌ Application Insights がこのプロジェクトで有効になっていません.\")\n",
    "    print(\"==> Azure AI Foundry ポータルの \\\"トレース\\\"タブから、Application Inights を有効にしてください.\")\n",
    "else:\n",
    "    configure_azure_monitor(connection_string=application_insights_connection_string)\n",
    "    print(\"✅ Application Insights によるトレースを有効にしました.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 評価データセットのアップロードを行います"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "リモート評価で利用する評価用のデータセットが含まれたファイルを AI プロジェクトにアップロードします。\n",
    "\n",
    "評価用のデータは、評価する項目に合わせて、JSON リスト形式で以下の内容を用意します。個々のデータで用意するプロパティは以下の内容となります。\n",
    "- `query`: ユーザーがシステムに対して行う質問やクエリを指します\n",
    "- `context`: システムが応答を生成する際に利用する、関連情報や背景情報を指します\n",
    "- `response`: システムが `query` と `context` に基づいて生成した応答、回答、または、出力を指します\n",
    "- `ground_truth`: `query` に対する理想的な正解となる回答や模範解答を指します\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tracer.start_as_current_span(\"quick_start_04: upload_evaluation_file\")\n",
    "def upload_evaluation_file():\n",
    "  # Upload data for evaluation and get dataset id\n",
    "  data_id, _ = project.upload_file(\"./data/eval_data_ja.jsonl\")\n",
    "  return data_id\n",
    "\n",
    "data_id = upload_evaluation_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 評価項目を定義する\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Azure AI Foundry で対応する AI 品質評価は以下の通りです。\n",
    "\n",
    "リモート評価で評価する項目を決めて定義します。ここでは、以下の項目について、品質評価を指定します。\n",
    "\n",
    "\n",
    "- AI 品質 (AI 支援)\n",
    "\n",
    "    評価項目は以下の通りです。\n",
    "\n",
    "    | 項目 | クラス | 説明 |\n",
    "    | --- | -- | -- |\n",
    "    | 根拠性 | GroundednessEvaluator | 生成 AI アプリケーションで生成された回答が、入力ソースからの情報とどの程度一致しているかを計測します。 |\n",
    "    | 関連性 | RelevanceEvaluator | 生成 AI アプリケーションで生成された回答がどの程度適切で、提示された質問に直接関連するかを計測します。 |\n",
    "    | コヒーレンス | CoherenceEvaluator | 生成 AI アプリケーションが、スムーズに流れ、自然に読み取られ、人間のような言語に似た出力を生成できる程度を測定します。 |\n",
    "    | 流暢性 | FluencyEvaluator | 生成 AI アプリケーションの予測応答の言語習熟度を測定します。 |\n",
    "    | 類似性 | SimilarityEvaluator | ソース データ (グラウンド トゥルース) 文と生成 AI アプリケーションで生成された応答の間の類似性を計測します。 |\n",
    "    \n",
    "    評価データに必要となるプロパティは以下の通りです。\n",
    "    \n",
    "    | 項目 | query | context | response | ground_truth |\n",
    "    | --- | -- | -- | -- | -- |\n",
    "    | 根拠性      | ✅ | ✅ | ✅ |  |\n",
    "    | 関連性      | ✅ |  | ✅ |  |\n",
    "    | コヒーレンス | ✅ |  | ✅ |  |\n",
    "    | 流暢性      |  |  | ✅ |  |\n",
    "    | 類似性      | ✅ |  | ✅ | ✅ |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects.models import ConnectionType\n",
    "from azure.ai.projects.models import EvaluatorConfiguration\n",
    "from azure.ai.evaluation import (\n",
    "    GroundednessEvaluator, RelevanceEvaluator, CoherenceEvaluator,\n",
    "    FluencyEvaluator, SimilarityEvaluator)\n",
    "\n",
    "\n",
    "@tracer.start_as_current_span(\"quick_start_04: get_evaluators\")\n",
    "def get_evaluators():\n",
    "    default_connection = project.connections.get_default(\n",
    "        connection_type=ConnectionType.AZURE_OPEN_AI\n",
    "    )\n",
    "    model_config = default_connection.to_evaluator_model_config(\n",
    "        deployment_name=model_name_string, api_version=model_api_version_string, include_credentials=True,\n",
    "    )\n",
    "    evaluators={\n",
    "        \"groundedness\": EvaluatorConfiguration(id=GroundednessEvaluator.id, init_params={\"model_config\": model_config}),\n",
    "        \"relevance\": EvaluatorConfiguration(id=RelevanceEvaluator.id, init_params={\"model_config\": model_config}),\n",
    "        \"coherence\": EvaluatorConfiguration(id=CoherenceEvaluator.id, init_params={\"model_config\": model_config}),\n",
    "        \"fluency\": EvaluatorConfiguration(id=FluencyEvaluator.id, init_params={\"model_config\": model_config}),\n",
    "        \"similarity\": EvaluatorConfiguration(id=SimilarityEvaluator.id, init_params={\"model_config\": model_config}),\n",
    "    }\n",
    "    return evaluators\n",
    "\n",
    "evaluators = get_evaluators()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. AI プロジェクトで評価を実行します\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "アップロードした評価データセットに対して、定義した評価項目で、AI プロジェクト上で評価を実行します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from azure.ai.projects.models import Evaluation, Dataset\n",
    "\n",
    "@tracer.start_as_current_span(\"quick_start_04: run_remote_evaluation\")\n",
    "def run_remote_evaluation(data_id, evaluators):\n",
    "    evaluation = Evaluation(\n",
    "        display_name=f\"リモート評価 - {time.strftime(\"%Y%m%d%H%M%S\")}\",\n",
    "        description=f\"リモート評価 - {time.strftime(\"%Y%m%d%H%M%S\")}: サンプルデータセットの評価テスト\",\n",
    "        data=Dataset(id=data_id),\n",
    "        evaluators=evaluators,\n",
    "    )\n",
    "    evaluation_response = project.evaluations.create(evaluation=evaluation)\n",
    "    return evaluation_response\n",
    "\n",
    "eval_response = run_remote_evaluation(data_id, evaluators)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 評価の実行結果を取得します。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "評価結果は、Azure AI Foundry ポータルで閲覧することができます。\n",
    "また、評価結果のレポートを取得することもできます。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eval_response)\n",
    "\n",
    "get_evaluation_response = project.evaluations.get(eval_response.id)\n",
    "print(\"------------------------------------------------------------------------\")\n",
    "print(\"Created evaluation, evaluation ID: \", get_evaluation_response.id)\n",
    "print(\"Evaluation status: \", get_evaluation_response.status)\n",
    "if isinstance(get_evaluation_response.properties, dict):\n",
    "    print(\"AI Foundry URI: \", get_evaluation_response.properties[\"AiStudioEvaluationUri\"])\n",
    "print(\"------------------------------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
